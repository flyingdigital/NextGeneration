## 第二周培训

培训内容主要为**Python爬虫**，需要说明的是爬虫的代码时间久后可能无法运行(网页更新)，故主要学习一种思路。

- [环境](#环境)
- [一些文档](#一些文档)
- [文本爬虫](#文本爬虫)
- [图片爬虫](#图片爬虫)
- [音频爬虫](#音频爬虫)
- [视频爬虫](#视频爬虫)
- [Ajax爬虫](#Ajax爬虫)

### 环境

- Python3.8
- Pycharm
- requests
- re

### 一些文档

- [正则](https://deerchao.cn/tutorials/regex/regex.htm)
- [requests](https://requests.readthedocs.io/en/master/)
- [Http协议](https://developer.mozilla.org/zh-CN/docs/Web/HTTP)

### 文本爬虫

选择爬取的网站为人民日报。

```
import requests
import re

'''
思路
获取网页->从网页上找到自己想要的内容->提取内容
'''

# 爬取前的准备
# url
url = 'http://paper.people.com.cn/rmrb/html/2020-11/14/nw.D110000renmrb_20201114_8-01.htm'
# 请求头信息
headers = {
    'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:82.0) Gecko/20100101 Firefox/82.0',
}

# 获取响应头
response = requests.get(url,headers=headers)
# 解决响应头编码问题
# 查看响应头编码  print(response.encoding)
response.encoding = response.apparent_encoding

# 使用正则匹配需要内容
# 主副标题
main_title = re.findall('class="article".*?<h1>(.*?)</h1>',response.text,re.S)[0]   # 返回一个列表
sub_title = re.findall('class="article".*?<h2>(.*?)</h2>',response.text,re.S)[0]
# 发布日期
date = re.findall('<span class="date">(.*?)</span>',response.text,re.S)[1]
# 文章内容
article = re.findall('<P>(.*?)</P>',response.text,re.S)

# 转换样式
# date转换央视
date = re.sub('[\r\t\n ]','',date)
date = re.sub('&nbsp;',' ',date)
# article转换样式
for i in range(len(article)):
    article[i] = re.sub('\u3000',' ',article[i])
    article[i] = re.sub('&nbsp;', ' ', article[i])

# 输出消息
print(main_title)
print(sub_title)
print(date)
for item in article:
    print(item)

# 查看html的内容
# print(response.text)

```



### 图片爬虫

为了方便举例，任选取人民日报上的图片进行爬取。

```
import requests
import re


'''
思路
获取网页->从网页上找到自己想要的图片->提取图片链接->获取保存图片
'''

# 爬取前的准备
# url
url = 'http://paper.people.com.cn/rmrb/html/2020-11/14/nw.D110000renmrb_20201114_8-01.htm'
# 请求头信息
headers = {
    'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:82.0) Gecko/20100101 Firefox/82.0',
}

# 获取响应头
response = requests.get(url,headers=headers)
# 解决响应头编码问题
# 查看响应头编码  print(response.encoding)
response.encoding = response.apparent_encoding

# 使用正则匹配需要内容
# 获取图片
image = re.findall('<div class="paper">.*?img.*?src=(.*?)</div>',response.text,re.S)[0]
# 去除掉多余内容
image = re.split(' ',image)[0]
print(image)
# 去掉../  真实图片路径
image = re.sub('(\.\./)','',image)

# 图片链接拼接
url = 'http://paper.people.com.cn/rmrb/'+image

# 获取图片并保存
img = requests.get(url,headers=headers).content
with open('a.jpg','wb') as f:
    f.write(img)

```

### 音频爬虫

```
import requests

'''
思路
    分析页面的json数据找到音频的外链->爬取音频
'''
url = 'http://m801.music.126.net/20201114154420/af0555c9a5dea9b6de911f1923d157c0/jdyyaac/obj/w5rDlsOJwrLDjj7CmsOj/4617774030/d528/2a2d/45e1/d27b6747c41e685914165ec9b4149efe.m4a'

headers = {
    'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:82.0) Gecko/20100101 Firefox/82.0',
}
response = requests.get(url,headers=headers)
with open('a.mp4','wb') as f:
    f.write(response.content)
```



### 视频爬虫

```
import requests


'''
    思路： 从视频页面分析出视频链接->爬取保存
'''

# url
url = 'https://video.pearvideo.com/mp4/adshort/20201114/cont-1706997-15483120_adpkg-ad_hd.mp4'
# 请求头信息
headers = {
    'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:82.0) Gecko/20100101 Firefox/82.0',
}
response = requests.get(url,headers=headers)

# 保存文件
with open('a.mp4','wb') as f:
    f.write(response.content)
```



### Ajax爬虫

详细请见音频爬虫。这里主要基于个人理解介绍Ajax。

所谓Ajax其实就是前端与后端通信的一个技术，这里与使用form表单提交对比。使用form表单向后台提交数据，页面会可见的刷新，而使用Ajax向后台提交数据，页面不需要刷新。而后台为了响应ajax提交的数据，会把从后端返回的数据变成一个接口(这里的接口指的是一个网页而不是语言或硬件接口)。而我们爬虫正是从这个接口里边把有用数据给捞出来。





